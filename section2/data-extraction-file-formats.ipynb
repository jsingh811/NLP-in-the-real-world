{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfaeba2",
   "metadata": {},
   "source": [
    "# Reading PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd6703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading PyPDF2-2.11.1-py3-none-any.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from PyPDF2) (3.10.0.2)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-2.11.1\n"
     ]
    }
   ],
   "source": [
    "! pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333084e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of pages: 1\n",
      "Contents of the first page:\n",
      "\n",
      "2⌅Natural Language Processing in the Real-World\n",
      "popular databases that are used widely for text data. Each database comes with ways\n",
      "to query and perform operations on text. We’ll implement some of these operations.\n",
      "Finally, we will introduce the concept of data maintenance and discuss some useful\n",
      "tips and tricks to prevent the data from corruption.\n",
      "This chapter includes the following sections.\n",
      "•Sources of data\n",
      "•Data extraction\n",
      "•Data storage\n",
      "1.2 SOURCES OF DATA\n",
      "1.2.1 Generated by businesses\n",
      "The most common source of text data is the data generated by the business’s opera-\n",
      "tions and is dependent on what the business does. For example, in real estate, sources\n",
      "of text data include property listing descriptions, agent comments, legal documents,\n",
      "and customer interaction data. For some other industry verticals, the source of text\n",
      "data can include social media posts, product descriptions, articles, web documents,\n",
      "chat data, or a combination thereof. When there is an absence of owned (ﬁrst-party)\n",
      "data, organizations leverage data from di\u0000erent vendors and clients. Overall, from a\n",
      "business’s standpoint, the commonly seen text data is of the following types.\n",
      "1.Customer reviews/comments\n",
      "User comments are a very common source of text, especially from social me-\n",
      "dia, e-commerce, and hospitality businesses that collect product reviews. For\n",
      "instance, Google and Yelp collect reviews across brands as well as small and\n",
      "large businesses.\n",
      "2.Social media/blog posts\n",
      "Social media posts and blogs ﬁnd presence in most types of businesses. In\n",
      "today’s world, social media reaches more people globally than any other form\n",
      "of media. Whether or not a business is directly associated with social media,\n",
      "there’s often social media presence of businesses, products, service promotions,\n",
      "articles, or more. On the other hand, there are many businesses o\u0000ering a\n",
      "product/service for analyzing the social media presence of other businesses.\n",
      "Whether one is gathering one’s own media data or on behalf of a client, there’s\n",
      "a rich volume of text associated which makes this a popular text data source\n",
      "that spans many industry verticals.\n",
      "3.Chat data\n",
      "E-commerce, banking, and many other industries leverage chat data. Chat data\n",
      "is essentially the chat history of messages exchanged between a business and\n",
      "its client or customer. This is a common source of text data in industries and is\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "with open(\"sample.pdf\", \"rb\") as pdf:\n",
    "    # Creating pdf reader object\n",
    "    pdf_reader = PdfFileReader(pdf)\n",
    " \n",
    "    # Fetching number of pages in the PDF\n",
    "    num_pages = pdf_reader.numPages\n",
    "    print(\n",
    "        \"Total no. of pages: {}\".format(num_pages)\n",
    "    )\n",
    "    if num_pages > 0:\n",
    "        # Creating a page object for the 1st page\n",
    "        # Replace 0 with 1 to access the 2nd page, \n",
    "        # and so on\n",
    "        page = pdf_reader.getPage(0)\n",
    "        # Extracting text from the page\n",
    "        text = page.extractText()\n",
    "        print(\"Contents of the first page:\\n\")\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669129b6",
   "metadata": {},
   "source": [
    "# Reading JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafd5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample written to json file: {'Mathew': ['mathematics', 'chemistry'], 'Perry': ['biology', 'arts']}\n",
      "Sample read from json file: {'Mathew': ['mathematics', 'chemistry'], 'Perry': ['biology', 'arts']}\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import json\n",
    "\n",
    "# Writing a sample dict to json file\n",
    "sample = {\n",
    "    \"Mathew\": [\"mathematics\", \"chemistry\"],\n",
    "    \"Perry\": [\"biology\", \"arts\"]\n",
    "}\n",
    "with open(\"sample.json\", \"w\") as f:\n",
    "    json.dump(sample, f)\n",
    "\n",
    "# Reading the json file back\n",
    "with open(\"sample.json\", \"r\") as f:\n",
    "    read_sample = json.load(f)\n",
    "\n",
    "# Printing\n",
    "print(\"Sample written to json file: {}\".format(sample))\n",
    "print(\"Sample read from json file: {}\".format(read_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730730ed",
   "metadata": {},
   "source": [
    "# Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8172dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row', ' name', ' age']\n",
      "[['1', ' Kim', ' 23'], ['2', ' Lowe', ' 45'], ['3', ' Beatrice', ' 55']]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import csv\n",
    "\n",
    "# Creating csv reader object\n",
    "with open(\"sample_csv.csv\", \"r\") as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    # If your file has a head, then\n",
    "    header = next(csvreader)\n",
    "    print(header)\n",
    "    # get rows in a list\n",
    "    rows = [row for row in csvreader]\n",
    "    print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b24b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row, name, age\\n']\n",
      "['1, Kim, 23\\n', '2, Lowe, 45\\n', '3, Beatrice, 55\\n']\n"
     ]
    }
   ],
   "source": [
    "file = open('sample_csv.csv')\n",
    "content = file.readlines()\n",
    "\n",
    "# If the first row is the header\n",
    "header = content[:1]\n",
    "\n",
    "# Fetching the rows\n",
    "rows = content[1:]\n",
    "\n",
    "# Printing header and rows\n",
    "print(header)\n",
    "print(rows)\n",
    "\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5a034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (1.3.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from pandas) (2021.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from pandas) (1.22.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a10d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row', ' name', ' age'], dtype='object')\n",
      "   row       name   age\n",
      "0    1        Kim    23\n",
      "1    2       Lowe    45\n",
      "2    3   Beatrice    55\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas datafrme\n",
    "data = pd.read_csv(\"sample_csv.csv\")\n",
    "\n",
    "# print column names\n",
    "print(data.columns)\n",
    "\n",
    "# print data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b60ce",
   "metadata": {},
   "source": [
    "# Reading from HTML page (web scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5bfce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (4.10.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from beautifulsoup4) (2.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56000fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " How would I go about counting the words in a sentence? I'm using Python.\n",
      "For example, I might have the string: \n",
      "string = \"I     am having  a   very  nice  23!@$      day. \"\n",
      "\n",
      "That would be 7 words. I'm having trouble with the random amount of spaces after/before each word as well as when numbers or symbols are involved.\n",
      "Top answer: \n",
      " str.split() without any arguments splits on runs of whitespace characters:\n",
      ">>> s = 'I am having a very nice day.'\n",
      ">>> \n",
      ">>> len(s.split())\n",
      "7\n",
      "\n",
      "From the linked documentation:\n",
      "\n",
      "If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# URL to questions\n",
    "myurl = \"\"\"https://stackoverflow.com/questions/19410018/how-to-count-the-number-of-words-in-a-sentence-ignoring-numbers-punctuation-an\"\"\"\n",
    "\n",
    "html = urlopen(myurl).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "question = soup.find(\"div\", {\"class\": \"question\"})\n",
    "\n",
    "# Print top 1000 characters of question to find relevant tag\n",
    "ques_text = question.find(\n",
    "    \"div\", {\"class\": \"s-prose js-post-body\"}\n",
    ")\n",
    "print(\"Question: \\n\", ques_text.get_text().strip())\n",
    "\n",
    "answers = soup.find(\"div\", {\"class\": \"answer\"})\n",
    "# print to check the correct class tag.\n",
    "\n",
    "ans_text = answers.find(\n",
    "    \"div\", {\"class\": \"s-prose js-post-body\"}\n",
    ")\n",
    "print(\"Top answer: \\n\", ans_text.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e823eb",
   "metadata": {},
   "source": [
    "# Reading a Word document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc36ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /Users/jyotikasingh/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from python-docx) (4.8.0)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=6831f2c608c0525b3e6c91266f4b4f8454ff8426933fb54710c73805293110fa\n",
      "  Stored in directory: /Users/jyotikasingh/Library/Caches/pip/wheels/83/8b/7c/09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.11\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33aa07d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common source of text data is the data generated by the business’s operations and is dependent on what the business does. For example, in real estate, sources of text data include property listing descriptions, agent comments, legal documents, and customer interaction data. For some other industry verticals, the source of text data can include social media posts, product descriptions, articles, web documents, chat data, or a combination thereof. When there is an absence of owned (ﬁrst-party) data, organizations leverage data from different vendors and clients. Overall, from a business’s standpoint, the commonly seen text data is of the following types.Customer reviews/commentsUser comments are a very common source of text, especially from social media, e-commerce, and hospitality businesses that collect product reviews. For instance, Google and Yelp collect reviews across brands as well as small and large businesses.Social media/blog postsSocial media posts and blogs ﬁnd presence in most types of businesses. In today’s world, social media reaches more people globally than any other form of media. Whether or not a business is directly associated with social media, there’s often social media presence of businesses, products, service promotions, articles, or more. On the other hand, there are many businesses offering a product/service for analyzing the social media presence of other businesses. Whether one is gathering one’s own media data or on behalf of a client, there’s a rich volume of text associated which makes this a popular text data source that spans many industry verticals.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from docx import Document\n",
    "\n",
    "doc = open(\"sample_word.docx\", \"rb\")\n",
    "document = Document(doc)\n",
    "\n",
    "# Placeholder for text\n",
    "doc_text=\"\"\n",
    "for para in document.paragraphs:\n",
    "    doc_text += para.text\n",
    "\n",
    "# Print the final output\n",
    "print(doc_text)\n",
    "\n",
    "# Close the file\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51c362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
