{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669d51af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of videos 522\n"
     ]
    }
   ],
   "source": [
    "# Getting data from YouTube\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "DEVELOPER_KEY = \"<enter your key>\"\n",
    "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
    "YOUTUBE_API_VERSION = 'v3'\n",
    "\n",
    "youtube = build(\n",
    "    YOUTUBE_API_SERVICE_NAME,\n",
    "    YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY\n",
    ")\n",
    "\n",
    "video_search_response = youtube.search().list(\n",
    "    q=\"python\",\n",
    "    part='id,snippet',\n",
    "    maxResults=50,\n",
    "    type='video',\n",
    "    relevanceLanguage=\"en\",\n",
    "    regionCode=\"US\"\n",
    ").execute()\n",
    "\n",
    "tkn = video_search_response[\"nextPageToken\"]\n",
    "videos = []\n",
    "while tkn and len(video_search_response[\"items\"]) > 0:\n",
    "    videos += video_search_response[\"items\"]\n",
    "    video_search_response = youtube.search().list(\n",
    "        q=\"python\",\n",
    "        part='id,snippet',\n",
    "        maxResults=50,\n",
    "        type='video',\n",
    "        pageToken=tkn,\n",
    "        relevanceLanguage=\"en\",\n",
    "        regionCode=\"US\"\n",
    "    ).execute()\n",
    "    tkn = video_search_response.get(\"nextPageToken\")\n",
    "\n",
    "print(\"Total no. of videos\", len(set([i[\"id\"][\"videoId\"] for i in videos])))\n",
    "\n",
    "\n",
    "dets = {\n",
    "        i[\"id\"][\"videoId\"]: {\n",
    "            \"title\": i[\"snippet\"][\"title\"], \n",
    "            \"description\": i[\"snippet\"][\"description\"]\n",
    "        }\n",
    "        for i in videos\n",
    "}\n",
    "video_text = [[k, \". \".join([i[\"title\"], i[\"description\"]])] for k,i in dets.items()]\n",
    "yt_text = [i[1] for i in video_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6592e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = \"Python Machine Learning Tutorial (Data Science) Python Machine Learning Tutorial - Learn how to predict the kind of music people like. Subscribe for more Python tutorials like ...\"\n",
    "sample_2 = \"Ball python bite I decided to grab a snake out of its tank without asking, this was totally my fault. But now I can say I've been bit by a snake\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a458e",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174fcd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "# get tfidf of all samples in the corpus\n",
    "tfidf = vect.fit_transform(yt_text)\n",
    "\n",
    "def tfidf_sim(sample_doc):\n",
    "    # get tfidf vector for sample document\n",
    "    selected_itm = vect.transform([sample_doc])\n",
    "\n",
    "    # similarity between sample doc and the rest of the corpus\n",
    "    cosine_sim = [\n",
    "        cosine_similarity(selected_itm, itm)[0][0] \n",
    "        for itm in tfidf\n",
    "    ]\n",
    "\n",
    "    # index of top 8 matches\n",
    "    indx_top8 = sorted(\n",
    "        range(len(cosine_sim)),\n",
    "        key=lambda i: cosine_sim[i],\n",
    "        reverse=True\n",
    "    )[:8]\n",
    "    return indx_top8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5792767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1_tfidf_top8 = tfidf_sim(sample_1)\n",
    "sample2_tfidf_top8 = tfidf_sim(sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af117e",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c6bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def spacy_sim(sample_doc):\n",
    "    docs_spacy = [nlp(\"u'\"+itm+\"'\") for itm in yt_text]\n",
    "    selected_itm = nlp(\"u'\"+sample_doc+\"'\")\n",
    "\n",
    "    # Similarity between sample doc and the rest of the corpus\n",
    "    spacy_sim = [\n",
    "        selected_itm.similarity(itm) for itm in docs_spacy\n",
    "    ]\n",
    "\n",
    "    # index of top 8 matches\n",
    "    indx_top8 = sorted(\n",
    "        range(len(spacy_sim)),\n",
    "        key=lambda i: spacy_sim[i],\n",
    "        reverse=True\n",
    "    )[:8]\n",
    "    return indx_top8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e5244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1_spacy_top8 = spacy_sim(sample_1)\n",
    "sample2_spacy_top8 = spacy_sim(sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c0fbb",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5aa8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "document_embeddings = bert_model.encode(yt_text)\n",
    "\n",
    "def bert_sim(sample_doc):\n",
    "    selected_itm = bert_model.encode(sample_doc)\n",
    "\n",
    "    # Similarity between sample doc and the rest of the corpus\n",
    "    bert_sim = [\n",
    "        util.pytorch_cos_sim(selected_itm, itm).item() \n",
    "        for itm in document_embeddings\n",
    "    ]\n",
    "\n",
    "    # index of top 8 matches\n",
    "    indx_top8 = sorted(\n",
    "        range(len(bert_sim)), \n",
    "        key=lambda i: bert_sim[i], \n",
    "        reverse=True)[:8]\n",
    "    return indx_top8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c400a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1_bert_top8 = bert_sim(sample_1)\n",
    "sample2_bert_top8 = bert_sim(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "675bb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video data can be accessed by the above return indices as video_text[inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c861b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
